# Image-Classification-in-Production-line

# Classification of Damaged Packaging using Machine Learning

## üìñ Introduction

In the manufacturing world, automation is crucial for optimizing production and ensuring that products are packaged efficiently[cite: 5]. However, packaging machines can occasionally produce defective packages due to minor deviations in the process[cite: 6]. When these defective packages are not detected, they can lead to financial losses, damage to the company's reputation, and customer dissatisfaction[cite: 7].

To mitigate this problem, this project proposes the use of machine learning to enhance the detection and classification of defective packages on a production line[cite: 9]. The goal is to develop and train deep learning models to accurately identify and classify packages as **intact** or **damaged**, thereby improving the quality control process and ensuring customer satisfaction[cite: 35].

## üë• Team

* Ariston Arag√£o
* F√°tima Ara√∫jo
* Jo√£o Teles
* Marcos Gabriel

---

## üìã Project Overview

The project is divided into four main phases, from model development to interpretation and comparison[cite: 36].

### 1. Model Training

The first phase involves developing and training **three distinct deep learning architectures** to classify package images as damaged or intact[cite: 38, 39]. Key considerations for this phase include[cite: 40]:
* **Transfer Learning:** Leveraging pre-trained models[cite: 40].
* **Data Augmentation:** Artificially expanding the training dataset[cite: 40].
* **Regularization:** Techniques to prevent overfitting[cite: 40].

---

### 2. Architecture Evaluation

Once trained, the three architectures will be rigorously evaluated on their performance[cite: 43]. This evaluation will include metrics such as **precision, recall, and F1-score**, considering the different camera angles (top and side)[cite: 44]. We will also analyze[cite: 45, 46]:
* The models' limitations[cite: 45].
* Interesting patterns in the errors[cite: 45].
* Bias and Variance[cite: 46].

---

### 3. Interpretability

To understand the models' decision-making process, we will use the **Integrated Gradients** method[cite: 48]. This will generate attribution maps that highlight the image regions most influential in the model's classification, helping to identify the specific areas (e.g., bounding boxes) the model focuses on[cite: 48, 49].

---

### 4. Comparison of Interpretation Maps

In the final phase, we will **compare the interpretation maps** generated by each architecture[cite: 52]. The objective is to assess how much importance each model gives to the pixels that actually represent the damaged region on the packages and to check for consistency in the results[cite: 53].

---

### ‚≠ê Bonus Task

As an additional challenge, the project will explore the possibility of **extracting and reading the serial number** that identifies each package from the images[cite: 56].

## üìä Dataset

The dataset for this project consists of **400 artificially generated RGB images** of packages on a production line conveyor belt[cite: 14, 15, 12].

* **Image Variability**: Each package is captured by two separate cameras: one from the **top** and one from the **side**[cite: 16, 17].
* **Identification**: Each package has a unique serial number reflected in the filename (e.g., `{sn}_side.png`)[cite: 18].
* **Dataset Structure**: The data is organized into `damage` and `intact` folders, with `side` and `top` subdirectories[cite: 19, 20, 21, 22, 23, 24, 25, 26]. A separate `interpretabilidade` directory is provided to be used as the test set[cite: 27, 31].